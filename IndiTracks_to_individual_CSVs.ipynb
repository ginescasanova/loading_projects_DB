{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import the necessary libraries \n",
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from openpyxl import load_workbook\n",
    "from urllib import parse \n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#2a. Set up credentials:\n",
    "\n",
    "# Get environmental variables:\n",
    "USERNAME = os.environ.get('O365_CCR_USERNAME')\n",
    "PASSWORD = os.environ.get('O365_CCR_PASSWORD')\n",
    "ROOT=os.environ.get('OneDrive') #the resulting CSVs are loaded in OneDrive before they are uploaded to SharePoint\n",
    "\n",
    "\n",
    "#read json config file:\n",
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    config = config[\"share_point\"]\n",
    "\n",
    "#extract variables from the json file to use them in code:\n",
    "url_hprs=config[\"site\"]\n",
    "selected_folder=config[\"inditracks_folder\"] #the intermediary OneDrive folder where the resulting CSVs are stored before they are uploaded into SharePoint\n",
    "\n",
    "file_destination=ROOT+selected_folder\n",
    "\n",
    "#2b. creates a dataframe with the sites and lists to be iterated:\n",
    "with open(\"General_ShP_sites.json\") as sites_file:\n",
    "    shp_sites = json.load(sites_file)\n",
    "\n",
    "df_shp_sites=pd.DataFrame(shp_sites)   \n",
    "\n",
    "current_inditracks=pd.read_csv(\"Current_IndiTracks.csv\", index_col=0)\n",
    "current_inditracks=current_inditracks.reset_index()\n",
    "timestamp=datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define function to connect to the SharePoint site:\n",
    "def autenticate_in_sharepoint(shp_url, USERNAME, PASSWORD):    \n",
    "    ctx_auth = AuthenticationContext(shp_url)\n",
    "    if ctx_auth.acquire_token_for_user(USERNAME, PASSWORD):\n",
    "        ctx = ClientContext(shp_url, ctx_auth)\n",
    "        web = ctx.web\n",
    "        ctx.load(web)\n",
    "        ctx.execute_query()\n",
    "        print (\"\")\n",
    "        print (\"\")\n",
    "        print (\"\")\n",
    "        print (\"\")\n",
    "\n",
    "        print(\"The Automat has connected to: {0}\".format(web.properties['Title']))\n",
    "\n",
    "    else:\n",
    "        print (\"\")\n",
    "        print (ctx_auth.get_last_error())\n",
    "        \n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Define function to process all tables and produce project dataframes:\n",
    "\n",
    "def download_inditrack (ctx, project_code, relative_url):\n",
    "    \n",
    "    print (\"\")\n",
    "    print(\"Project \" + project_code + \" is being processed...\")\n",
    "    \n",
    "    try:\n",
    "\n",
    "        #4a. Download the file:\n",
    "\n",
    "        response = File.open_binary(ctx, relative_url)\n",
    "\n",
    "        #save data to BytesIO stream\n",
    "        bytes_file_obj = io.BytesIO()\n",
    "        bytes_file_obj.write(response.content)\n",
    "        bytes_file_obj.seek(0) #set file object to start\n",
    "\n",
    "\n",
    "        #4b. Importing Excel spreadhseets with Pandas\n",
    "        #data=pd.ExcelFile(bytes_file_obj)\n",
    "        #print(data.sheet_names)\n",
    "\n",
    "        #4c. Importing Excel´s table objects inside of the workbook with openpyxl:\n",
    "\n",
    "        wb = load_workbook(bytes_file_obj, data_only=True)\n",
    "\n",
    "        print (\"\")\n",
    "        print(\"These are the available sheets in \" + project_code + \"´s workbook:\")\n",
    "        print(wb.sheetnames)\n",
    "\n",
    "        ws1 = wb[\"M&E Plan\"] #explore one specific sheet\n",
    "        #print(ws1.tables.items()) # list the tables inside of the selected sheet\n",
    "        ws2 = wb[\"Events\"] #explore one specific sheet\n",
    "        #print(ws2.tables.items()) # list the tables inside of the selected sheet\n",
    "        ws3 = wb[\"Milestones\"] #explore one specific sheet\n",
    "        #print(ws3.tables.items()) # list the tables inside of the selected sheet\n",
    "\n",
    "        sheets_list=[ws1,ws2,ws3]\n",
    "\n",
    "        #4d. Creating dataframes out of each excel table:\n",
    "        mapping = {}\n",
    "        for sheet in sheets_list:\n",
    "            for entry, data_boundary in sheet.tables.items():\n",
    "                #print(entry)\n",
    "                #print(data_boundary)\n",
    "                #parse the data within the ref boundary\n",
    "                data = sheet[data_boundary]\n",
    "                #extract the data \n",
    "                #the inner list comprehension gets the values for each cell in the table\n",
    "                content = [[cell.value for cell in ent] \n",
    "                           for ent in data\n",
    "                      ]\n",
    "\n",
    "                header = content[0]\n",
    "\n",
    "                #the contents ... excluding the header\n",
    "                rest = content[1:]\n",
    "\n",
    "                #create dataframe with the column names\n",
    "                #and pair table name with dataframe\n",
    "                df = pd.DataFrame(rest, columns = header)\n",
    "                mapping[entry] = df\n",
    "\n",
    "        Outcomes, Activities, Indicators, Milestones=mapping.values()\n",
    "\n",
    "        return Outcomes,Activities, Indicators, Milestones \n",
    "\n",
    "    except: \n",
    "        print(\"It has not been possible to load \" + project_code + \"'s workbook         #WARNING: failure on load in \" + project_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Define function that creates the DIM table for outcomes of type \"progress\":\n",
    "\n",
    "\n",
    "def dim_outc_progress (Outcomes, project_code, timestamp):\n",
    "    try:\n",
    "        DIM_outcome_progress = Outcomes\n",
    "        DIM_outcome_progress [\"Indicator level\"]=\"Outcomes\"\n",
    "        DIM_outcome_progress [\"Project Code\"]=project_code\n",
    "        DIM_outcome_progress [\"Version\"]= timestamp\n",
    "        DIM_outcome_progress [\"indicator_key\"]=DIM_outcome_progress [\"Project Code\"]+\"_\"+DIM_outcome_progress [\"Indicator ID\"]\n",
    "\n",
    "        DIM_outcome_progress = Outcomes[Outcomes[\"Indicator Type\"]==\"Progress\"][[\"indicator_key\",\"Project Code\",\"Indicator level\", \"Outcome ID\", \"Outcomes (O)\",\n",
    "                                            \"Indicator ID\",\"Definition of the indicator\", \"Overall target\", \"Indicator Total Weight in LogFrame)\",\n",
    "                                            \"Specification of the indicator (if needed after reading column D)\",\"Source of verification\",\n",
    "                                            \"Predicted number of events within this indicator\", \"Indicator Type\", \"Version\"]]\n",
    "\n",
    "        DIM_outcome_progress.rename(columns = {'Indicator Total Weight in LogFrame)':'Indicator Total Weight in LogFrame'}, inplace=True)\n",
    "\n",
    "\n",
    "        DIM_outcome_progress_indexed=DIM_outcome_progress.set_index(\"indicator_key\")\n",
    "        csv_name=project_code+\"_DIM_outcome_progress.csv\"\n",
    "        DIM_outcome_progress_indexed.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "\n",
    "        \n",
    "        print (\"\")\n",
    "        print (\"Setting outcome dataframes for \" + project_code)\n",
    "        print (\"\")\n",
    "        print (\"    'DIM_outcome_progress' created...\")\n",
    "        return DIM_outcome_progress\n",
    "    except:       \n",
    "        print (\"    'DIM_outcome_progress' creation failed...         #WARNING: failure on load in \" + project_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Define function that creates the dataframe \"outc_expected_time\" \n",
    "#by merging DIM Outcomes and Indicators, filtering, and implementing some adjustments:\n",
    "\n",
    "def outc_exp_time(DIM_outcome_progress, Indicators):\n",
    "    try:\n",
    "        outc_expected_time=DIM_outcome_progress.merge(Indicators, on=\"Indicator ID\")\n",
    "        outc_expected_time[\"event_key\"]=outc_expected_time [\"Project Code\"]+\"_\"+outc_expected_time [\"Event ID\"]\n",
    "\n",
    "\n",
    "        outc_expected_time= outc_expected_time[[\"event_key\",\"Project Code\",\"Activity_ID/Outcome_ID\",\"Indicator ID\",\"Description\",\"Event ID\",\n",
    "                                                    \"Planned date of the event (what is expected)\",\n",
    "                                                    \"Planned value of the indicator (what is expected)\", \"Indicator level\", \n",
    "                                                    \"Overall target\",\"Indicator Total Weight in LogFrame\",\"Indicator Type\",\n",
    "                                                    \"Version\"]]\n",
    "\n",
    "        outc_expected_time=outc_expected_time[(outc_expected_time[\"Indicator level\"]==\"Outcomes\") & (outc_expected_time[\"Indicator Type\"]==\"Progress\")]\n",
    "\n",
    "        #Creates calculated column \"Expected_progress_Outc\"\n",
    "        outc_expected_time[\"Expected_progress_Outc\"]=outc_expected_time[\"Planned value of the indicator (what is expected)\"]/outc_expected_time[\"Overall target\"]\n",
    "        #Creates calculated column \"Expected_Progress_Outc_Weighted\"\n",
    "        outc_expected_time[\"Expected_Progress_Outc_Weighted\"]=outc_expected_time[\"Expected_progress_Outc\"]*outc_expected_time[\"Indicator Total Weight in LogFrame\"]\n",
    "        #Format universal time into \"dd/mm/yyyy\"\n",
    "        outc_expected_time[\"Planned date of the event (what is expected)\"]=outc_expected_time[\"Planned date of the event (what is expected)\"].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "\n",
    "        outc_expected_time_indexed=outc_expected_time.set_index(\"event_key\")\n",
    "        csv_name=project_code+\"_outc_expected_time.csv\"\n",
    "        outc_expected_time_indexed.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "\n",
    "\n",
    "        print (\"    'outc_expected_time' created...\")\n",
    "\n",
    "        return outc_expected_time\n",
    "    \n",
    "    except:       \n",
    "        print (\"    'outc_expected_time' creation failed...         #WARNING: failure on load in \" + project_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Define function that creates the dataframe \"outc_reported_time\" \n",
    "#by merging DIM Outcomes and Indicators, filtering, and implementing some adjustments:\n",
    "\n",
    "\n",
    "def outc_rep_time(DIM_outcome_progress, Indicators):\n",
    "    try:\n",
    "        outc_reported_time=DIM_outcome_progress.merge(Indicators, on=\"Indicator ID\")\n",
    "        outc_reported_time[\"event_key\"]=outc_reported_time [\"Project Code\"]+\"_\"+outc_reported_time [\"Event ID\"]\n",
    "\n",
    "        outc_reported_time= outc_reported_time[[\"event_key\",\"Project Code\",\"Activity_ID/Outcome_ID\",\"Indicator ID\",\"Description\",\"Event ID\",\n",
    "                                                    \"Actual date of the event (when it really happened)\",\n",
    "                                                    \"Value of the indicator (real value after event)\", \"Indicator level\", \n",
    "                                                    \"Overall target\",\"Indicator Total Weight in LogFrame\",\"Indicator Type\",\n",
    "                                                    \"Version\"]]\n",
    "\n",
    "        outc_reported_time=outc_reported_time[(outc_reported_time[\"Indicator level\"]==\"Outcomes\") & (outc_reported_time[\"Indicator Type\"]==\"Progress\")]\n",
    "\n",
    "        #Drop non-reported values:\n",
    "        outc_reported_time=outc_reported_time.dropna()\n",
    "\n",
    "        \n",
    "        #Create calculated column \"Real Progress\"\n",
    "        outc_reported_time[\"Real Progress\"]=outc_reported_time[\"Value of the indicator (real value after event)\"]/outc_reported_time[\"Overall target\"]\n",
    "\n",
    "        #Format universal time into \"dd/mm/yyyy\"\n",
    "        outc_reported_time[\"Actual date of the event (when it really happened)\"]=outc_reported_time[\"Actual date of the event (when it really happened)\"].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "        outc_reported_time_indexed=outc_reported_time.set_index(\"event_key\")\n",
    "        csv_name=project_code+\"_outc_reported_time.csv\"\n",
    "        outc_reported_time_indexed.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "\n",
    "        \n",
    "        print (\"    'outc_reported_time' created...\")\n",
    "\n",
    "        return outc_reported_time\n",
    "    \n",
    "    except:       \n",
    "        print (\"    'outc_reported_time' creation failed...         #WARNING: failure on load in \" + project_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Define function that creates the dataframe \"Outcome_Progress_Top\" through additions to \"outc_reported_time\":\n",
    "\n",
    "def outc_time_top(DIM_outcome_progress, outc_reported_time):\n",
    "    try:\n",
    "        outcome_progress_top = outc_reported_time[[\"Indicator ID\",\"Real Progress\"]]\n",
    "\n",
    "        outcome_progress_top=outcome_progress_top.groupby(by=\"Indicator ID\",dropna=True).sum()\n",
    "\n",
    "        outcome_progress_top.rename(columns = {'Real Progress':'Sum_of_Progress'}, inplace=True)\n",
    "\n",
    "        outcome_progress_top= outcome_progress_top.merge(DIM_outcome_progress, on=\"Indicator ID\")\n",
    "\n",
    "        outcome_progress_top=outcome_progress_top[[\"indicator_key\",\"Project Code\", \"Indicator ID\", \"Indicator Total Weight in LogFrame\", \"Sum_of_Progress\", \"Version\"]]\n",
    "\n",
    "        outcome_progress_top_indexed=outcome_progress_top.set_index(\"indicator_key\", inplace=True)\n",
    "        csv_name=project_code+\"_outc_progress_top.csv\"\n",
    "        outcome_progress_top.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "        \n",
    "        \n",
    "        print (\"    'outcome_progress_top' created...\")\n",
    "\n",
    "        return outcome_progress_top\n",
    "\n",
    "    except:       \n",
    "        print (\"    'outcome_progress_top' creation failed...         #WARNING: failure on load in \" + project_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Define function that creates the DIM dataframe for activity indicators of type \"progress\":\n",
    "\n",
    "\n",
    "def dim_act_progress (Activities, project_code, timestamp):\n",
    "\n",
    "    try:\n",
    "        DIM_activities_progress = Activities\n",
    "\n",
    "        DIM_activities_progress [\"Indicator level\"]=\"Activities\"\n",
    "        DIM_activities_progress [\"Project Code\"]=project_code\n",
    "        DIM_activities_progress [\"Version\"]= timestamp\n",
    "        DIM_activities_progress [\"indicator_key\"]=DIM_activities_progress[\"Project Code\"]+\"_\"+DIM_activities_progress[\"Indicator ID\"]\n",
    "\n",
    "        #Filter \"progress\" rows and select columns\n",
    "        DIM_activities_progress = Activities[Activities[\"Indicator Type\"]==\"Progress\"][[\"indicator_key\",\"Project Code\",\"Indicator level\", \n",
    "                                            \"Activity ID\", \"Activities (Output) (A)\", \"Indicator ID\",\"Definition of the indicator\",\n",
    "                                            \"Overall target\", \"Indicator Total Weight in LogFrame\",\n",
    "                                            \"Specification of the indicator (if needed after reading column D)\",\"Source of verification\", \n",
    "                                            \"Predicted number of events within this indicator\", \"Indicator Type\",\"Version\"]]\n",
    "\n",
    "        DIM_activities_progress_indexed=DIM_activities_progress.set_index(\"indicator_key\")\n",
    "        csv_name=project_code+\"_DIM_activities_progress.csv\"\n",
    "        DIM_activities_progress_indexed.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "       \n",
    "    \n",
    "        print (\"\")\n",
    "        print (\"Setting activities dataframes for \" + project_code)\n",
    "        print (\"\")\n",
    "        print (\"    'DIM_activities_progress' created...\")\n",
    "\n",
    "        return DIM_activities_progress\n",
    "    \n",
    "    except:\n",
    "        print (\"    'DIM_activities_progress' creation failed...         #WARNING: failure on load in \" + project_code)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Define function that creates the dataframe \"act_expected_time\" \n",
    "#by merging DIM Activities and Indicators, filtering, and implementing some adjustments:\n",
    "\n",
    "def act_exp_time(DIM_activities_progress, Indicators):\n",
    "    try:\n",
    "        act_expected_time=DIM_activities_progress.merge(Indicators, on=\"Indicator ID\")\n",
    "        act_expected_time[\"event_key\"]=act_expected_time[\"Project Code\"]+\"_\" +act_expected_time[\"Event ID\"]\n",
    "\n",
    "        act_expected_time= act_expected_time[[\"event_key\",\"Project Code\",\"Activity_ID/Outcome_ID\",\"Indicator ID\",\"Description\",\"Event ID\",\n",
    "                                                    \"Planned date of the event (what is expected)\",\n",
    "                                                    \"Planned value of the indicator (what is expected)\", \"Indicator level\", \n",
    "                                                    \"Overall target\",\"Indicator Total Weight in LogFrame\",\"Indicator Type\",\"Version\"]]\n",
    "\n",
    "        act_expected_time=act_expected_time[(act_expected_time[\"Indicator level\"]==\"Activities\") & (act_expected_time[\"Indicator Type\"]==\"Progress\")]\n",
    "\n",
    "        #Creates calculated column \"Expected_progress\"\n",
    "        act_expected_time[\"Expected_progress\"]=act_expected_time[\"Planned value of the indicator (what is expected)\"]/act_expected_time[\"Overall target\"]\n",
    "        #Creates calculated column \"Expected_Progress_Weighted\"\n",
    "        act_expected_time[\"Expected_Progress_Weighted\"]=act_expected_time[\"Expected_progress\"]*act_expected_time[\"Indicator Total Weight in LogFrame\"]\n",
    "        #Format universal time into \"dd/mm/yyyy\"\n",
    "        act_expected_time[\"Planned date of the event (what is expected)\"]=act_expected_time[\"Planned date of the event (what is expected)\"].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "        act_expected_time_indexed=act_expected_time.set_index(\"event_key\")\n",
    "        csv_name=project_code+\"_act_expected_time.csv\"\n",
    "        act_expected_time_indexed.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "\n",
    "        \n",
    "        \n",
    "        print (\"    'act_expected_time' created...\")\n",
    "\n",
    "\n",
    "        return act_expected_time\n",
    "   \n",
    "    except:       \n",
    "        print (\"    'act_expected_time' creation failed...         #WARNING: failure on load in \" + project_code)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Define function that creates the dataframe \"act_reported_time\" \n",
    "#by merging DIM Activities and Indicators, filtering, and implementing some adjustments:\n",
    "\n",
    "\n",
    "def act_rep_time(DIM_activities_progress, Indicators):\n",
    "\n",
    "    try:\n",
    "        act_reported_time=DIM_activities_progress.merge(Indicators, on=\"Indicator ID\")\n",
    "        act_reported_time[\"event_key\"]=act_reported_time[\"Project Code\"]+\"_\" +act_reported_time[\"Event ID\"]\n",
    "\n",
    "        act_reported_time= act_reported_time[[\"event_key\",\"Project Code\", \"Activity_ID/Outcome_ID\",\"Indicator ID\",\"Description\",\"Event ID\",\n",
    "                                                    \"Actual date of the event (when it really happened)\",\n",
    "                                                    \"Value of the indicator (real value after event)\", \"Indicator level\", \n",
    "                                                    \"Overall target\",\"Indicator Total Weight in LogFrame\",\"Indicator Type\", \"Version\"]]\n",
    "\n",
    "        act_reported_time=act_reported_time[(act_reported_time[\"Indicator level\"]==\"Activities\") & (act_reported_time[\"Indicator Type\"]==\"Progress\")]\n",
    "\n",
    "        #Drop non-reported values:\n",
    "        act_reported_time=act_reported_time.dropna()\n",
    "\n",
    "        #Create calculated column \"Real_progress\"\n",
    "        act_reported_time[\"Real_progress\"]=act_reported_time[\"Value of the indicator (real value after event)\"]/act_reported_time[\"Overall target\"]\n",
    "\n",
    "        #Format universal time into \"dd/mm/yyyy\"\n",
    "        act_reported_time[\"Actual date of the event (when it really happened)\"]=act_reported_time[\"Actual date of the event (when it really happened)\"].dt.strftime('%d/%m/%Y')\n",
    "        \n",
    "        act_reported_time_indexed=act_reported_time.set_index(\"event_key\")\n",
    "        csv_name=project_code+\"_act_reported_time.csv\"\n",
    "        act_reported_time_indexed.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "\n",
    "        \n",
    "        \n",
    "        print (\"    'act_reported_time' created...\")\n",
    "\n",
    "        return act_reported_time\n",
    "    \n",
    "    except:\n",
    "        print (\"    'act_reported_time' creation failed...         #WARNING: failure on load in \" + project_code)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. Define a function that creates the dataframe \"Activity_Progress_Top\" through additions to \"act_reported_time\":\n",
    "\n",
    "def act_time_top(DIM_activities_progress, act_reported_time):\n",
    "\n",
    "    try:\n",
    "\n",
    "        activity_progress_top = act_reported_time[[\"Indicator ID\",\"Real_progress\"]]\n",
    "\n",
    "        activity_progress_top=activity_progress_top.groupby(by=\"Indicator ID\").sum()\n",
    "\n",
    "        activity_progress_top.rename(columns = {'Real_progress':'Sum_of_Progress'}, inplace=True)\n",
    "\n",
    "        activity_progress_top= activity_progress_top.merge(DIM_activities_progress, on=\"Indicator ID\")\n",
    "\n",
    "        activity_progress_top=activity_progress_top[[\"indicator_key\",\"Project Code\", \"Indicator ID\", \"Indicator Total Weight in LogFrame\", \"Sum_of_Progress\", \"Version\"]]\n",
    "\n",
    "        activity_progress_top_indexed=activity_progress_top.set_index(\"Indicator ID\", inplace=True)\n",
    "        csv_name=project_code+\"_activity_progress_top.csv\"\n",
    "        activity_progress_top.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "\n",
    "        \n",
    "        print (\"    'activity_progress_top' created...\")\n",
    "\n",
    "        return activity_progress_top\n",
    "\n",
    "    except:       \n",
    "        print (\"    'activity_progress_top' creation failed...         #WARNING: failure on load in \" + project_code)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. Define a function that creates the dataframe \"Milestones\":\n",
    "def milestones_df(Milestones,project_code, timestamp):\n",
    "    try:\n",
    "        milestones=Milestones\n",
    "        milestones.rename(columns = {'Progress expected':'Progress expected (%)'}, inplace=True)\n",
    "        milestones[\"Project Code\"]=project_code\n",
    "        milestones[\"Version\"]=timestamp\n",
    "        milestones[\"milestone_key\"]=milestones[\"Project Code\"]+milestones[\"Event ID\"]\n",
    "        milestones=milestones[[\"milestone_key\",\"Project Code\",\"Indicator ID\",\"Event ID\",\"Description of the milestone\",\"Progress expected (%)\",\"Version\"]]\n",
    "\n",
    "        milestones_indexed=milestones.set_index(\"milestone_key\")\n",
    "        csv_name=project_code+\"_milestones.csv\"\n",
    "        milestones_indexed.to_csv(file_destination+csv_name)\n",
    "        upload_file_to_sharepoint(file_destination,csv_name)\n",
    "\n",
    "\n",
    "        print (\"\")\n",
    "        print (\"Setting milestones dataframe for \" + project_code)\n",
    "        print (\"\")\n",
    "        print (\"    'milestones' created...\")\n",
    "\n",
    "        return milestones\n",
    "\n",
    "    except:       \n",
    "        print (\"    'milestones' creation failed...         #WARNING: failure on load\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. Steps to upload the resulting CSV files to SharePoint:\n",
    "def upload_file_to_sharepoint(source_folder,file_name):\n",
    "      \n",
    "    #a. Reads the file in OneDrive:\n",
    "    path=source_folder+file_name\n",
    "    with open(path, 'rb') as content_file:\n",
    "        file_content = content_file.read()\n",
    "    \n",
    "    #b. Connecting to the desired folder in the tennant:\n",
    "    target_url=\"/sites/Group-HPRS/Sdilene%20dokumenty/Data_loads-Do_not_modify/individual_inditracks\"\n",
    "    target_folder = ctx2.web.get_folder_by_server_relative_url(target_url)\n",
    "\n",
    "    #c. Upload the file to SharePoint\n",
    "    name = os.path.basename(path)\n",
    "    target_file = target_folder.upload_file(name, file_content).execute_query()    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country Project_code\n",
      "0    Moldova         MD26\n",
      "1    Moldova         MD27\n",
      "2    Georgia         GE41\n",
      "3    Georgia         GE43\n",
      "4    Georgia         GE46\n",
      "5    Georgia         GE52\n",
      "6     Zambia         ZM18\n",
      "7     Zambia         ZM25\n",
      "8     Zambia         ZM29\n",
      "9     Zambia         ZM32\n",
      "10  Mongolia         MN20\n",
      "11      Iraq         IR24\n",
      "12     Iraq2         IR23\n",
      "13  Mongolia         MN19\n",
      "14   Georgia         GE53\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: Group - HPRS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: Group - Georgia\n",
      "\n",
      "Project GE41 is being processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the available sheets in GE41´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for GE41\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for GE41\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for GE41\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for GE41 has been sucessful\n",
      "\n",
      "Project GE43 is being processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the available sheets in GE43´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for GE43\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for GE43\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for GE43\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for GE43 has been sucessful\n",
      "\n",
      "Project GE46 is being processed...\n",
      "\n",
      "These are the available sheets in GE46´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for GE46\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for GE46\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for GE46\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for GE46 has been sucessful\n",
      "\n",
      "Project GE52 is being processed...\n",
      "\n",
      "These are the available sheets in GE52´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for GE52\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for GE52\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for GE52\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for GE52 has been sucessful\n",
      "\n",
      "Project GE53 is being processed...\n",
      "\n",
      "These are the available sheets in GE53´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for GE53\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for GE53\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for GE53\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for GE53 has been sucessful\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: Group - Africa\n",
      "\n",
      "Project ZM18 is being processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the available sheets in ZM18´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for ZM18\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for ZM18\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for ZM18\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for ZM18 has been sucessful\n",
      "\n",
      "Project ZM25 is being processed...\n",
      "\n",
      "These are the available sheets in ZM25´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for ZM25\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for ZM25\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for ZM25\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for ZM25 has been sucessful\n",
      "\n",
      "Project ZM29 is being processed...\n",
      "\n",
      "These are the available sheets in ZM29´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for ZM29\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for ZM29\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for ZM29\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for ZM29 has been sucessful\n",
      "\n",
      "Project ZM32 is being processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the available sheets in ZM32´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for ZM32\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for ZM32\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for ZM32\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for ZM32 has been sucessful\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: Group - Iraq\n",
      "\n",
      "Project IR24 is being processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the available sheets in IR24´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for IR24\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for IR24\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for IR24\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for IR24 has been sucessful\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: Group - Mongolia\n",
      "\n",
      "Project MN20 is being processed...\n",
      "\n",
      "These are the available sheets in MN20´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for MN20\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for MN20\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for MN20\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for MN20 has been sucessful\n",
      "\n",
      "Project MN19 is being processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the available sheets in MN19´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for MN19\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for MN19\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for MN19\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for MN19 has been sucessful\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: Group - Moldova\n",
      "\n",
      "Project MD26 is being processed...\n",
      "\n",
      "These are the available sheets in MD26´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for MD26\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for MD26\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for MD26\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for MD26 has been sucessful\n",
      "\n",
      "Project MD27 is being processed...\n",
      "\n",
      "These are the available sheets in MD27´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for MD27\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for MD27\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for MD27\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for MD27 has been sucessful\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: Group -  GRV\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Golem has connected to: UNDP-IR23\n",
      "\n",
      "Project IR23 is being processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\gincas\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the available sheets in IR23´s workbook:\n",
      "['M&E Plan', 'Events', 'Milestones', 'SoV - optional', 'Data dictionary']\n",
      "\n",
      "Setting outcome dataframes for IR23\n",
      "\n",
      "    'DIM_outcome_progress' created...\n",
      "    'outc_expected_time' created...\n",
      "    'outc_reported_time' created...\n",
      "    'outcome_progress_top' created...\n",
      "\n",
      "Setting activities dataframes for IR23\n",
      "\n",
      "    'DIM_activities_progress' created...\n",
      "    'act_expected_time' created...\n",
      "    'act_reported_time' created...\n",
      "    'activity_progress_top' created...\n",
      "\n",
      "Setting milestones dataframe for IR23\n",
      "\n",
      "    'milestones' created...\n",
      "\n",
      "Iteration for IR23 has been sucessful\n"
     ]
    }
   ],
   "source": [
    "#15. Run program and create individual CSVs for each project:\n",
    "print(current_inditracks[['Country', 'Project_code']])\n",
    "ctx2=autenticate_in_sharepoint(url_hprs,USERNAME,PASSWORD) #function n.3, for uploading docs to HPRS SharePoint\n",
    "\n",
    "for index, row in df_shp_sites.iterrows():\n",
    "    shp_country = row['country']\n",
    "    url = row['site']\n",
    "    try:\n",
    "        ctx=autenticate_in_sharepoint(url,USERNAME,PASSWORD) #function n.3, for dowloading tables from each Country SharePoint\n",
    "\n",
    "        for index, row in current_inditracks.iterrows():\n",
    "            project_code= row['Project_code']\n",
    "            inditrack_country=row['Country']\n",
    "            relative_url=row['IndiTrack_Relative_url']\n",
    "\n",
    "            if shp_country ==inditrack_country:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    Outcomes,Activities, Indicators, Milestones = download_inditrack(ctx, project_code, relative_url) #function n.4\n",
    "\n",
    "                    #14a. Create csv for DIM_outcome_progress: \n",
    "                    DIM_outcome_progress =dim_outc_progress(Outcomes, project_code, timestamp) #function n.5\n",
    "\n",
    "                    #14b. Create csv for outc_expected_time:\n",
    "                    outc_expected_time = outc_exp_time(DIM_outcome_progress, Indicators) #function n.6\n",
    "\n",
    "                    #14c. Create csv for outc_reported_time:\n",
    "                    outc_reported_time = outc_rep_time(DIM_outcome_progress, Indicators) #function n.7\n",
    "\n",
    "                    #14d. Create csv for outcome_progress_top:\n",
    "                    outcome_progress_top = outc_time_top(DIM_outcome_progress, outc_reported_time) #function n.8\n",
    "\n",
    "                    #14e. Create csv for DIM_activities_progress:\n",
    "                    DIM_activities_progress = dim_act_progress (Activities, project_code, timestamp) #function n.9\n",
    "\n",
    "                    #14f. Create csv for act_expected_time:\n",
    "                    act_expected_time = act_exp_time(DIM_activities_progress, Indicators) #function n.10\n",
    "\n",
    "                    #14g. Create csv for act_reported_time:\n",
    "                    act_reported_time = act_rep_time(DIM_activities_progress, Indicators) #function n.11\n",
    "\n",
    "                    #14h. Create csv for activity_progress_top:\n",
    "                    activity_progress_top = act_time_top(DIM_activities_progress, act_reported_time) #function n.12\n",
    "\n",
    "                    #14i. Create csv for milestones:\n",
    "                    milestones= milestones_df(Milestones,project_code, timestamp) #function n.13\n",
    "\n",
    "                    print (\"\")\n",
    "                    print('Iteration for ' + project_code + ' has been sucessful')        \n",
    "\n",
    "                except:       \n",
    "                    print (\"\")\n",
    "                    print('Iteration for ' + project_code + ' has been cancelled')\n",
    "\n",
    "                    \n",
    "    except:\n",
    "        print(\"The Automat has failed to connect to \" + shp_country + \"'s SharePoint site\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
